@article{rainforth2018inference,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.09550},
  primaryClass = {stat},
  title = {Inference {{Trees}}: {{Adaptive Inference}} with {{Exploration}}},
  shorttitle = {Inference {{Trees}}},
  abstract = {We introduce inference trees (ITs), a new class of inference methods that build on ideas from Monte Carlo tree search to perform adaptive sampling in a manner that balances exploration with exploitation, ensures consistency, and alleviates pathologies in existing adaptive methods. ITs adaptively sample from hierarchical partitions of the parameter space, while simultaneously learning these partitions in an online manner. This enables ITs to not only identify regions of high posterior mass, but also maintain uncertainty estimates to track regions where significant posterior mass may have been missed. ITs can be based on any inference method that provides a consistent estimate of the marginal likelihood. They are particularly effective when combined with sequential Monte Carlo, where they capture long-range dependencies and yield improvements beyond proposal adaptation alone.},
  journal = {arXiv:1806.09550 [stat]},
  author = {Rainforth, Tom and Zhou, Yuan and Lu, Xiaoyu and Teh, Yee Whye and Wood, Frank and Yang, Hongseok and {van de Meent}, Jan-Willem},
  month = jun,
  year = {2018},
  keywords = {Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/janwillem/Zotero/storage/M8NE39ZK/Rainforth - 2018 - Inference Trees.pdf}
}

@article{vandemeent_arxiv_2014,
    author = {van de Meent, Jan-Willem and Paige, Brooks, and Wood, Frank},
    abstract = {In this paper we demonstrate that tempering Markov chain Monte Carlo samplers for Bayesian models by recursively subsampling observations without replacement can improve the performance of baseline samplers in terms of effective sample size per computation.  We present two tempering by subsampling algorithms, subsampled parallel tempering and subsampled tempered transitions.  We provide an asymptotic analysis of the computational cost of tempering by subsampling, verify that tempering by subsampling costs less than traditional tempering, and demonstrate both algorithms on Bayesian approaches to learning the mean of a high dimensional multivariate Normal and estimating Gaussian process hyperparameters.},
    journal = {ArXiv e-prints},
    archivePrefix = {arXiv},
    eprint = {1401.7145},
    page = {1401.7145},
    title = {{Tempering by Subsampling}},
    year = {2014}
}
